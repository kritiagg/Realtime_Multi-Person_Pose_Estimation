{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/home/kriti/caffe/python')\n",
    "import caffe\n",
    "CAFFE_HOME=\"/home/kriti/caffe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import cv2 as cv \n",
    "import numpy as np\n",
    "import scipy\n",
    "import PIL.Image\n",
    "import math\n",
    "import caffe\n",
    "import time\n",
    "from config_reader import config_reader\n",
    "import util\n",
    "import copy\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_image = '../sample_image/side.jpg'\n",
    "#test_image = '../sample_image/upper.jpg'\n",
    "#test_image = '../sample_image/upper2.jpg'\n",
    "\n",
    "def resize_img(file1):\n",
    "    size = 224\n",
    "    data = PIL.Image.open(file1)#.convert('L')\n",
    "    data.thumbnail((size,size), PIL.Image.ANTIALIAS)\n",
    "    img = data.resize((size,size))\n",
    "#     plt.imshow(img)\n",
    "    testfile = \"test.jpg\"\n",
    "    scipy.misc.imsave(testfile, img)\n",
    "\n",
    "resize_img(test_image)\n",
    "test_image = 'test.jpg'\n",
    "oriImg = cv.imread(test_image) # B,G,R order\n",
    "# f = plt.imshow(oriImg[:,:,[2,1,0]]) # reorder it before displaying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5, 1.0, 1.5, 2.0]\n"
     ]
    }
   ],
   "source": [
    "param, model = config_reader()\n",
    "param['use_gpu'] = 0\n",
    "print(param['scale_search'])\n",
    "param['scale_search'] = [1.0]\n",
    "multiplier = [x * model['boxsize'] / oriImg.shape[0] for x in param['scale_search']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if param['use_gpu']: \n",
    "    caffe.set_mode_gpu()\n",
    "    caffe.set_device(param['GPUdeviceNumber']) # set to your device!\n",
    "else:\n",
    "    caffe.set_mode_cpu()\n",
    "net = caffe.Net(model['deployFile'], model['caffemodel'], caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368, 368, 3)\n",
      "At scale 0, The CNN took 15839.49 ms.\n",
      "CPU times: user 15.6 s, sys: 280 ms, total: 15.9 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "heatmap_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 19))\n",
    "paf_avg = np.zeros((oriImg.shape[0], oriImg.shape[1], 38))\n",
    "# # first figure shows padded images\n",
    "# f, axarr = plt.subplots(1, len(multiplier))\n",
    "# f.set_size_inches((20, 5))\n",
    "# # second figure shows heatmaps\n",
    "# f2, axarr2 = plt.subplots(1, len(multiplier))\n",
    "# f2.set_size_inches((20, 5))\n",
    "# # third figure shows PAFs\n",
    "# f3, axarr3 = plt.subplots(2, len(multiplier))\n",
    "# f3.set_size_inches((20, 10))\n",
    "\n",
    "for m in range(len(multiplier)):\n",
    "    scale = multiplier[m]\n",
    "    imageToTest = cv.resize(oriImg, (0,0), fx=scale, fy=scale, interpolation=cv.INTER_CUBIC)\n",
    "    imageToTest_padded, pad = util.padRightDownCorner(imageToTest, model['stride'], model['padValue'])\n",
    "    print imageToTest_padded.shape\n",
    "    \n",
    "#     axarr[m].imshow(imageToTest_padded[:,:,[2,1,0]])\n",
    "#     axarr[m].set_title('Input image: scale %d' % m)\n",
    "\n",
    "    net.blobs['data'].reshape(*(1, 3, imageToTest_padded.shape[0], imageToTest_padded.shape[1]))\n",
    "    #net.forward() # dry run\n",
    "    net.blobs['data'].data[...] = np.transpose(np.float32(imageToTest_padded[:,:,:,np.newaxis]), (3,2,0,1))/256 - 0.5;\n",
    "    start_time = time.time()\n",
    "    output_blobs = net.forward()\n",
    "    print('At scale %d, The CNN took %.2f ms.' % (m, 1000 * (time.time() - start_time)))\n",
    "\n",
    "    # extract outputs, resize, and remove padding\n",
    "    heatmap = np.transpose(np.squeeze(net.blobs[output_blobs.keys()[1]].data), (1,2,0)) # output 1 is heatmaps\n",
    "    heatmap = cv.resize(heatmap, (0,0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n",
    "    heatmap = heatmap[:imageToTest_padded.shape[0]-pad[2], :imageToTest_padded.shape[1]-pad[3], :]\n",
    "    heatmap = cv.resize(heatmap, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv.INTER_CUBIC)\n",
    "    \n",
    "    paf = np.transpose(np.squeeze(net.blobs[output_blobs.keys()[0]].data), (1,2,0)) # output 0 is PAFs\n",
    "    paf = cv.resize(paf, (0,0), fx=model['stride'], fy=model['stride'], interpolation=cv.INTER_CUBIC)\n",
    "    paf = paf[:imageToTest_padded.shape[0]-pad[2], :imageToTest_padded.shape[1]-pad[3], :]\n",
    "    paf = cv.resize(paf, (oriImg.shape[1], oriImg.shape[0]), interpolation=cv.INTER_CUBIC)\n",
    "    \n",
    "    \n",
    "    # visualization\n",
    "#     axarr2[m].imshow(oriImg[:,:,[2,1,0]])\n",
    "#     ax2 = axarr2[m].imshow(heatmap[:,:,15], alpha=.5) # right wrist x face\n",
    "#     axarr2[m].set_title('Heatmaps (Rwri): scale %d' % m)\n",
    "    \n",
    "#     axarr3.flat[m].imshow(oriImg[:,:,[2,1,0]])\n",
    "#     ax3x = axarr3.flat[m].imshow(paf[:,:,16], alpha=.5) # right elbow\n",
    "#     axarr3.flat[m].set_title('PAFs (x comp. of Rwri to Relb): scale %d' % m)\n",
    "#     axarr3.flat[len(multiplier) + m].imshow(oriImg[:,:,[2,1,0]])\n",
    "#     ax3y = axarr3.flat[len(multiplier) + m].imshow(paf[:,:,17], alpha=.5) # right wrist\n",
    "#     axarr3.flat[len(multiplier) + m].set_title('PAFs (y comp. of Relb to Rwri): scale %d' % m)\n",
    "    \n",
    "    heatmap_avg = heatmap_avg + heatmap / len(multiplier)\n",
    "    paf_avg = paf_avg + paf / len(multiplier)\n",
    "\n",
    "# f2.subplots_adjust(right=0.93)\n",
    "# cbar_ax = f2.add_axes([0.95, 0.15, 0.01, 0.7])\n",
    "# _ = f2.colorbar(ax2, cax=cbar_ax)\n",
    "\n",
    "# f3.subplots_adjust(right=0.93)\n",
    "# cbar_axx = f3.add_axes([0.95, 0.57, 0.01, 0.3])\n",
    "# _ = f3.colorbar(ax3x, cax=cbar_axx)\n",
    "# cbar_axy = f3.add_axes([0.95, 0.15, 0.01, 0.3])\n",
    "# _ = f3.colorbar(ax3y, cax=cbar_axy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look on those averaged heatmaps and PAFs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.imshow(oriImg[:,:,[2,1,0]])\n",
    "# # print(heatmap_avg[:,:,0]) #eye :14 and 15\n",
    "# plt.imshow(heatmap_avg[:,:,1], alpha=.5)\n",
    "# fig = matplotlib.pyplot.gcf()\n",
    "# cax = matplotlib.pyplot.gca()\n",
    "# fig.set_size_inches(20, 20)\n",
    "# fig.subplots_adjust(right=0.93)\n",
    "# cbar_ax = fig.add_axes([0.95, 0.15, 0.01, 0.7])\n",
    "# _ = fig.colorbar(ax2, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from numpy import ma\n",
    "# # eyes orientation\n",
    "# U = paf_avg[:,:,34] * -1\n",
    "# V = paf_avg[:,:,35]\n",
    "# X, Y = np.meshgrid(np.arange(U.shape[1]), np.arange(U.shape[0]))\n",
    "# M = np.zeros(U.shape, dtype='bool')\n",
    "# M[U**2 + V**2 < 0.5 * 0.5] = True\n",
    "# print(len(paf_avg))\n",
    "# U = ma.masked_array(U, mask=M)\n",
    "# V = ma.masked_array(V, mask=M)\n",
    "\n",
    "# # 1\n",
    "# plt.figure()\n",
    "# plt.imshow(oriImg[:,:,[2,1,0]], alpha = .5)\n",
    "# s = 5\n",
    "# Q = plt.quiver(X[::s,::s], Y[::s,::s], U[::s,::s], V[::s,::s], \n",
    "#                scale=50, headaxislength=4, alpha=.5, width=0.001, color='r')\n",
    "\n",
    "# fig = matplotlib.pyplot.gcf()\n",
    "# fig.set_size_inches(20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 100, 19)\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "print heatmap_avg.shape\n",
    "\n",
    "#plt.imshow(heatmap_avg[:,:,2])\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "all_peaks = []\n",
    "peak_counter = 0\n",
    "\n",
    "# for all the 18 parts in the body\n",
    "for part in range(19-1):\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    map_ori = heatmap_avg[:,:,part]\n",
    "    map = gaussian_filter(map_ori, sigma=3)\n",
    "    \n",
    "    map_left = np.zeros(map.shape)\n",
    "    map_left[1:,:] = map[:-1,:]\n",
    "    map_right = np.zeros(map.shape)\n",
    "    map_right[:-1,:] = map[1:,:]\n",
    "    map_up = np.zeros(map.shape)\n",
    "    map_up[:,1:] = map[:,:-1]\n",
    "    map_down = np.zeros(map.shape)\n",
    "    map_down[:,:-1] = map[:,1:]\n",
    "    \n",
    "    peaks_binary = np.logical_and.reduce((map>=map_left, map>=map_right, map>=map_up, map>=map_down, map > param['thre1']))\n",
    "    peaks = zip(np.nonzero(peaks_binary)[1], np.nonzero(peaks_binary)[0]) # note reverse\n",
    "    peaks_with_score = [x + (map_ori[x[1],x[0]],) for x in peaks]\n",
    "    id = range(peak_counter, peak_counter + len(peaks))\n",
    "    peaks_with_score_and_id = [peaks_with_score[i] + (id[i],) for i in range(len(id))]\n",
    "\n",
    "    all_peaks.append(peaks_with_score_and_id)\n",
    "    peak_counter += len(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 15 is the id for right eye, 14 for left eye, 0 for nose\n",
    "# faces = 0\n",
    "# for i in all_peaks:\n",
    "#     if(i[14])\n",
    "#         faces +=1\n",
    "# left_eyes = len(np.array(all_peaks[14]))\n",
    "# right_eyes = len(np.array(all_peaks[15]))\n",
    "# noses = len(np.array(all_peaks[0]))\n",
    "# print(\"No. of people facing you:\",len(np.array(all_peaks[15])))\n",
    "# print(\"paf_avg\",len(paf_avg[:,:,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_peaks[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find connection in the specified sequence, center 29 is in the position 15\n",
    "limbSeq = [[2,3], [2,6], [3,4], [4,5], [6,7], [7,8], [2,9], [9,10], \\\n",
    "           [10,11], [2,12], [12,13], [13,14], [2,1], [1,15], [15,17], \\\n",
    "           [1,16], [16,18], [3,17], [6,18]]\n",
    "# the middle joints heatmap correpondence\n",
    "mapIdx = [[31,32], [39,40], [33,34], [35,36], [41,42], [43,44], [19,20], [21,22], \\\n",
    "          [23,24], [25,26], [27,28], [29,30], [47,48], [49,50], [53,54], [51,52], \\\n",
    "          [55,56], [37,38], [45,46]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connection_all = []\n",
    "special_k = []\n",
    "mid_num = 10\n",
    "\n",
    "for k in range(len(mapIdx)):\n",
    "    score_mid = paf_avg[:,:,[x-19 for x in mapIdx[k]]]\n",
    "    candA = all_peaks[limbSeq[k][0]-1]\n",
    "    candB = all_peaks[limbSeq[k][1]-1]\n",
    "    nA = len(candA)\n",
    "    nB = len(candB)\n",
    "    indexA, indexB = limbSeq[k]\n",
    "    if(nA != 0 and nB != 0):\n",
    "        connection_candidate = []\n",
    "        for i in range(nA):\n",
    "            for j in range(nB):\n",
    "                vec = np.subtract(candB[j][:2], candA[i][:2])\n",
    "                norm = math.sqrt(vec[0]*vec[0] + vec[1]*vec[1])\n",
    "                vec = np.divide(vec, norm)\n",
    "                \n",
    "                startend = zip(np.linspace(candA[i][0], candB[j][0], num=mid_num), \\\n",
    "                               np.linspace(candA[i][1], candB[j][1], num=mid_num))\n",
    "                \n",
    "                vec_x = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 0] \\\n",
    "                                  for I in range(len(startend))])\n",
    "                vec_y = np.array([score_mid[int(round(startend[I][1])), int(round(startend[I][0])), 1] \\\n",
    "                                  for I in range(len(startend))])\n",
    "\n",
    "                score_midpts = np.multiply(vec_x, vec[0]) + np.multiply(vec_y, vec[1])\n",
    "                if(norm == 0):\n",
    "                    norm = 1\n",
    "                score_with_dist_prior = sum(score_midpts)/len(score_midpts) + min(0.5*oriImg.shape[0]/norm-1, 0)\n",
    "                criterion1 = len(np.nonzero(score_midpts > param['thre2'])[0]) > 0.8 * len(score_midpts)\n",
    "                criterion2 = score_with_dist_prior > 0\n",
    "                if criterion1 and criterion2:\n",
    "                    connection_candidate.append([i, j, score_with_dist_prior, score_with_dist_prior+candA[i][2]+candB[j][2]])\n",
    "\n",
    "        connection_candidate = sorted(connection_candidate, key=lambda x: x[2], reverse=True)\n",
    "        connection = np.zeros((0,5))\n",
    "        for c in range(len(connection_candidate)):\n",
    "            i,j,s = connection_candidate[c][0:3]\n",
    "            if(i not in connection[:,3] and j not in connection[:,4]):\n",
    "                connection = np.vstack([connection, [candA[i][3], candB[j][3], s, i, j]])\n",
    "                if(len(connection) >= min(nA, nB)):\n",
    "                    break\n",
    "\n",
    "        connection_all.append(connection)\n",
    "    else:\n",
    "        special_k.append(k)\n",
    "        connection_all.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# last number in each row is the total parts number of that person\n",
    "# the second last number in each row is the score of the overall configuration\n",
    "subset = -1 * np.ones((0, 20))\n",
    "candidate = np.array([item for sublist in all_peaks for item in sublist])\n",
    "\n",
    "for k in range(len(mapIdx)):\n",
    "    if k not in special_k:\n",
    "        partAs = connection_all[k][:,0]\n",
    "        partBs = connection_all[k][:,1]\n",
    "        indexA, indexB = np.array(limbSeq[k]) - 1\n",
    "\n",
    "        for i in range(len(connection_all[k])): #= 1:size(temp,1)\n",
    "            found = 0\n",
    "            subset_idx = [-1, -1]\n",
    "            for j in range(len(subset)): #1:size(subset,1):\n",
    "                if subset[j][indexA] == partAs[i] or subset[j][indexB] == partBs[i]:\n",
    "                    subset_idx[found] = j\n",
    "                    found += 1\n",
    "            \n",
    "            if found == 1:\n",
    "                j = subset_idx[0]\n",
    "                if(subset[j][indexB] != partBs[i]):\n",
    "                    subset[j][indexB] = partBs[i]\n",
    "                    subset[j][-1] += 1\n",
    "                    subset[j][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "            elif found == 2: # if found 2 and disjoint, merge them\n",
    "                j1, j2 = subset_idx\n",
    "                print \"found = 2\"\n",
    "                membership = ((subset[j1]>=0).astype(int) + (subset[j2]>=0).astype(int))[:-2]\n",
    "                if len(np.nonzero(membership == 2)[0]) == 0: #merge\n",
    "                    subset[j1][:-2] += (subset[j2][:-2] + 1)\n",
    "                    subset[j1][-2:] += subset[j2][-2:]\n",
    "                    subset[j1][-2] += connection_all[k][i][2]\n",
    "                    subset = np.delete(subset, j2, 0)\n",
    "                else: # as like found == 1\n",
    "                    subset[j1][indexB] = partBs[i]\n",
    "                    subset[j1][-1] += 1\n",
    "                    subset[j1][-2] += candidate[partBs[i].astype(int), 2] + connection_all[k][i][2]\n",
    "\n",
    "            # if find no partA in the subset, create a new subset\n",
    "            elif not found and k < 17:\n",
    "                row = -1 * np.ones(20)\n",
    "                row[indexA] = partAs[i]\n",
    "                row[indexB] = partBs[i]\n",
    "                row[-1] = 2\n",
    "                row[-2] = sum(candidate[connection_all[k][i,:2].astype(int), 2]) + connection_all[k][i][2]\n",
    "                subset = np.vstack([subset, row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('found people with low confidence:', 0)\n"
     ]
    }
   ],
   "source": [
    "# delete some rows of subset which has few parts occur\n",
    "deleteIdx = [];\n",
    "for i in range(len(subset)):\n",
    "    if subset[i][-1] < 4 or subset[i][-2]/subset[i][-1] < 0.4:\n",
    "        deleteIdx.append(i) \n",
    "print(\"found people with low confidence:\",len(deleteIdx))\n",
    "subset = np.delete(subset, deleteIdx, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of persons present in the picture:', 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of persons present in the picture:\",len(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('No. of people facing you:', 0)\n"
     ]
    }
   ],
   "source": [
    "#### 15 is the id for right eye, 14 for left eye, 0 for nose\n",
    "faces = 0\n",
    "for i in subset:\n",
    "    if(i[14] !=-1 or i[15] != -1 or i[0] !=-1):\n",
    "        faces +=1\n",
    "\n",
    "print(\"No. of people facing you:\",faces)\n",
    "# print(\"paf_avg\",len(paf_avg[:,:,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # visualize\n",
    "# colors = [[255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0], [85, 255, 0], [0, 255, 0], \\\n",
    "#           [0, 255, 85], [0, 255, 170], [0, 255, 255], [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], \\\n",
    "#           [170, 0, 255], [255, 0, 255], [255, 0, 170], [255, 0, 85]]\n",
    "# cmap = matplotlib.cm.get_cmap('hsv')\n",
    "\n",
    "# canvas = cv.imread(test_image) # B,G,R order\n",
    "\n",
    "# for i in range(18):\n",
    "#     rgba = np.array(cmap(1 - i/18. - 1./36))\n",
    "#     rgba[0:3] *= 255\n",
    "#     for j in range(len(all_peaks[i])):\n",
    "#         cv.circle(canvas, all_peaks[i][j][0:2], 4, colors[i], thickness=-1)\n",
    "\n",
    "# to_plot = cv.addWeighted(oriImg, 0.3, canvas, 0.7, 0)\n",
    "# plt.imshow(to_plot[:,:,[2,1,0]])\n",
    "# fig = matplotlib.pyplot.gcf()\n",
    "# fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # visualize 2\n",
    "# stickwidth = 4\n",
    "\n",
    "# for i in range(17):\n",
    "#     for n in range(len(subset)):\n",
    "#         index = subset[n][np.array(limbSeq[i])-1]\n",
    "#         if -1 in index:\n",
    "#             continue\n",
    "#         cur_canvas = canvas.copy()\n",
    "#         Y = candidate[index.astype(int), 0]\n",
    "#         X = candidate[index.astype(int), 1]\n",
    "#         mX = np.mean(X)\n",
    "#         mY = np.mean(Y)\n",
    "#         length = ((X[0] - X[1]) ** 2 + (Y[0] - Y[1]) ** 2) ** 0.5\n",
    "#         angle = math.degrees(math.atan2(X[0] - X[1], Y[0] - Y[1]))\n",
    "#         polygon = cv.ellipse2Poly((int(mY),int(mX)), (int(length/2), stickwidth), int(angle), 0, 360, 1)\n",
    "#         cv.fillConvexPoly(cur_canvas, polygon, colors[i])\n",
    "#         canvas = cv.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\n",
    "        \n",
    "# plt.imshow(canvas[:,:,[2,1,0]])\n",
    "# fig = matplotlib.pyplot.gcf()\n",
    "# fig.set_size_inches(12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Number of persons present in the picture:\",len(subset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
